{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "008fad1a-1d6a-4cef-b92c-260e29944e5e",
   "metadata": {},
   "source": [
    "## Getting filings from the SEC's EDGAR database and turning it into enterprise leads\n",
    "\n",
    "1. Process the data into one large dataset. First we'll download everything and then convert it to bianary to speed up the processing times\n",
    "2. Narrow the companies down to your ICP (we'll use the SIC number) -- figure out the relative size of each company (we'll do total assets)\n",
    "3. get the latest filing & chunk the data into smaller sections. use gpt-3.5 to do this. Save the chuck position that has the data most relevent to you. \n",
    "4. Pass the best material to gpt-4 for find the companies where we have the best value prop. \n",
    "5. Retreive linkedIn info & good luck to you.\n",
    "\n",
    "This downloading and processing time's should be about an hour\n",
    "\n",
    "## To make this work\n",
    "1. Have the packages from the import section installed\n",
    "2. go through the document and rewrite each path for your system and where you want the data imported and exported\n",
    "3. fill out the code and prompt section \n",
    "\n",
    "## WARNING \n",
    "\n",
    "It will cost ~ $.20 - .60 for each gpt-3 extraction cycle\n",
    "\n",
    "It will cost ~ $.00 - .40 for each gpt-4 output. \n",
    "\n",
    "If you do this with every SEC filed company it will cost ~$500-2600. Depending on how the gpt-3.5 model is filtering relevence. \n",
    "\n",
    "## If you are changing sic codes\n",
    "\n",
    "start at where the first CSV is being compiled, I put a \"start here\" text box above it, and go through the next cells sequentially. \n",
    "\n",
    "## Last note\n",
    "\n",
    "My Jupyter Notebook has more memory allocated to it, if you're are having issues with the first CSV output, message me and i'll walk you through it\n",
    "\n",
    "GL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2e6f39e-a926-40c5-bb63-117c25cfdda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d512bb0-fb10-4083-83f7-f4b3339ad3d8",
   "metadata": {},
   "source": [
    "## Case Study\n",
    "\n",
    "You are on the revops/sales ops team @ a cybersecurity startup and you are trying to go after enterprise accounts. We are looking at the 'packaged software' sic code (see link for your use case) and you are trying to extract out relevant information from SEC filings and give actionable information to your team. \n",
    "\n",
    "The two prompts below are for the extraction and summary, adjust to your use case.\n",
    "\n",
    "#### The extraction Prompt MUST return a 1 or 0\n",
    "1 if relevant, 0 if irrelevant \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "198f3e75-26dc-4b1b-9b3c-b398d2c93475",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill out this section for you specific use case\n",
    "## use this lookup table to find your particular industry: \n",
    "## https://www.sec.gov/corpfin/division-of-corporation-finance-standard-industrial-classification-sic-code-list\n",
    "## \n",
    "## you need to write a prompt for the information extraction on the 10-Q\n",
    "## you need to write a prompt for the synthesis \n",
    "##\n",
    "## The current SIC I've selected is for software companies\n",
    "## We are pretending to be a cybersecurity company that helps enterprise clients manage their database infrastructure\n",
    "\n",
    "sic_code = 7372\n",
    "open_ai_key = \"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\"\n",
    "extraction_prompt = \"You are an analyst at a cybersecurity company. You will return '1' if the following section of an SEC filing is related to cybersecurity, digital threats, and IT security and '0' if it is not.\"\n",
    "summary_prompt = \"You are a sales analyst at a cybersecurity company. Summarize the enterprise customer's cybersecurity pain points dirved from the following data. We specialize in data breach prevention and are trying to understand how to properly position our digital security solutions to this company. Referance the give text as much as possible when extracting out the relevent pain points and have a heavy focus on the impact a solution will bring to the business, be as verbose as possible while maintaining accuracy:\"\n",
    "number_of_filings_to_process = 10\n",
    "\n",
    "## number_of_filings_to_process restricts the number of filing that are being processed. \n",
    "## if you want all of them to process set the number higher than the total amount of records in the first .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ce0daf1a-bc5c-4856-bdbf-f5a4f3d07dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pip install py-xbrl==2.2.10\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen, Request\n",
    "from urllib.error import HTTPError\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas\n",
    "import io\n",
    "from zipfile import ZipFile, BadZipFile\n",
    "from io import BytesIO\n",
    "import json\n",
    "from pprint import pprint\n",
    "from lxml import etree, html\n",
    "from xbrl.instance import XbrlParser, XbrlInstance\n",
    "from xbrl.cache import HttpCache\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d3f9fb7f-2327-4fa4-9606-39da43d39388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2023, '09'), (2023, '10'), (2023, '11'), (2023, '12'), (2024, '01')]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec_path = Path('../../data1/sec_data/10Q')\n",
    "sec_url = 'https://www.sec.gov'\n",
    "fsn_path = 'files/dera/data/financial-statement-and-notes-data-sets/'\n",
    "\n",
    "\n",
    "filing_periods = [(d.year, f'{d.month:02d}') for d in pd.date_range('2023-09-01', '2024-01-31', freq='MS')]\n",
    "filing_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2c034f06-df39-44e7-9ceb-cf026bce156f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:32<00:00, 42.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HTTPError 404: Not Found - https://www.sec.gov/files/dera/data/financial-statement-and-notes-data-sets/2024_01_notes.zip\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for yr, mm in tqdm(filing_periods):\n",
    "    # Make the directory\n",
    "    path = sec_path / f'{yr}_{mm}' / 'source'\n",
    "    if not path.exists():\n",
    "        path.mkdir(parents=True)\n",
    "\n",
    "    filing_url = f'{yr}_{mm}_notes.zip'\n",
    "    whole_url = sec_url + '/' + fsn_path + filing_url\n",
    "\n",
    "    try:\n",
    "        headers = {'User-Agent': 'Bjorn (bjornnobear@gmail.com)'}\n",
    "        # Feel free to email me\n",
    "        with urlopen(Request(whole_url, headers=headers)) as zipresp:\n",
    "            with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "                for file in zfile.namelist():\n",
    "                    local_file = path / file\n",
    "                    if local_file.exists():\n",
    "                        continue\n",
    "                    with local_file.open('wb') as output_file:\n",
    "                        for line in zfile.open(file).readlines():\n",
    "                            output_file.write(line)\n",
    "                    \n",
    "    except HTTPError as e:\n",
    "        print(f'\\nHTTPError {e.code}: {e.reason} - {whole_url}\\n')\n",
    "        continue\n",
    "    except BadZipFile:\n",
    "        print(f'\\nBad Zip File: {yr} {mm}\\n')\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b0721276-8fe4-4c0d-b035-7b4e04ffc38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:33<00:00,  1.06s/it]\n"
     ]
    }
   ],
   "source": [
    "## let's make all those file binary\n",
    "for file in tqdm(list(sec_path.glob('**/*.tsv'))):\n",
    "    \n",
    "  parquet_path = file.parent.parent / 'parquet'\n",
    "  if not parquet_path.exists():\n",
    "    parquet_path.mkdir(parents=True)\n",
    "\n",
    "  parquet_name = file.stem + '.parquet'\n",
    "  if not (parquet_path / parquet_name).exists():\n",
    "    try:\n",
    "      df = pd.read_csv(file, sep='\\t', encoding='latin1', low_memory=False, on_bad_lines='skip')\n",
    "      df.to_parquet(parquet_path / parquet_name)\n",
    "    except Exception as e:\n",
    "      print(e, ' [from] ', file)\n",
    "    else:\n",
    "      file.unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b6987e-f428-4969-9be3-0e6789b8ef53",
   "metadata": {},
   "source": [
    "## Start here for new SIC codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0c0f7bb2-b849-4e4a-ad18-2f5a43bfb567",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 239/239 [01:56<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated CSV file saved to: ../../data1/sec_data/10Q/latest_filings_with_assets_for_sic_7372.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## you'll get the lastest 10-Q filings for all companies with your SIC code & their total assets\n",
    "## \n",
    "## it takes a little while to get going, be patient. We want the assets to properly weight our propsects. \n",
    "\n",
    "\n",
    "def convert_date_format(date_str):\n",
    "    date_str = str(int(date_str))  # Ensure it's a string without decimal\n",
    "    return datetime.strptime(date_str, '%Y%m%d').strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "def fetch_and_parse_xbrl(cik, adsh, instance, parser):\n",
    "    logging.info(f\"Fetching and parsing XBRL for CIK: {cik}, ADSH: {adsh}\")\n",
    "    xbrl_url = f'https://www.sec.gov/Archives/edgar/data/{cik}/{adsh.replace(\"-\", \"\")}/{instance}'\n",
    "    xbrl_instance = parser.parse_instance(xbrl_url)\n",
    "    return json.loads(xbrl_instance.json(override_fact_ids=True))\n",
    "\n",
    "\n",
    "def find_asset_values(json_data, concept, target_period):\n",
    "    first_value_found = False\n",
    "    previous_value = None\n",
    "    for key, value in json_data.get('facts', {}).items():\n",
    "        dimensions = value.get('dimensions', {})\n",
    "        if len(dimensions) == 4 and dimensions.get('concept') == concept:\n",
    "            period = dimensions.get('period')\n",
    "            if first_value_found:\n",
    "                if period < target_period:\n",
    "                    return previous_value, value.get('value')\n",
    "            else:\n",
    "                if period == target_period:\n",
    "                    first_value_found = True\n",
    "                    previous_value = value.get('value')\n",
    "    return previous_value, None\n",
    "\n",
    "cache = HttpCache('./cache')\n",
    "headers = {'From': 'bjorn@bjorn.com', 'User-Agent': 'bjorn'}\n",
    "cache.set_headers(headers)\n",
    "parser = XbrlParser(cache)\n",
    "\n",
    "\n",
    "base_path = Path('../../data1/sec_data/10Q')\n",
    "sub_df = pd.DataFrame()\n",
    "for year_month_dir in base_path.iterdir():\n",
    "    if year_month_dir.is_dir():\n",
    "        parquet_file = year_month_dir / 'parquet' / 'sub.parquet'\n",
    "        if parquet_file.exists():\n",
    "            df = pd.read_parquet(parquet_file)\n",
    "            sub_df = pd.concat([sub_df, df], ignore_index=True)\n",
    "\n",
    "\n",
    "filtered_filings = sub_df[(sub_df['form'] == '10-Q') & (sub_df['sic'] == sic_code)]\n",
    "latest_filings = filtered_filings.sort_values(by=['cik', 'filed'], ascending=[True, False]).drop_duplicates(subset='cik')\n",
    "\n",
    "\n",
    "latest_filings['period'] = latest_filings['period'].apply(convert_date_format)\n",
    "\n",
    "\n",
    "latest_filings['current_assets'] = None\n",
    "for index, row in tqdm(latest_filings.iterrows(), total=latest_filings.shape[0]):\n",
    "    try:\n",
    "        target_period = row['period']\n",
    "        json_data = fetch_and_parse_xbrl(row['cik'], row['adsh'], row['instance'], parser)\n",
    "        current_value, _ = find_asset_values(json_data, \"Assets\", target_period)\n",
    "        latest_filings.at[index, 'current_assets'] = current_value\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing CIK {row['cik']}: {e}\")\n",
    "\n",
    "\n",
    "csv_output_path = Path(f'../../data1/sec_data/10Q/latest_filings_with_assets_for_sic_{sic_code}.csv')\n",
    "latest_filings.to_csv(csv_output_path, index=False)\n",
    "print(f\"Updated CSV file saved to: {csv_output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7013a59d-097a-4214-9920-c9396f766485",
   "metadata": {},
   "source": [
    "## Let's extract out the enterprise customers' pain points\n",
    "\n",
    "1. Load up the .csv & then retrieve the filing's raw text file. \n",
    "2. break the text file into chunks\n",
    "3. have gpt-3.5 do a gross search of the items we need\n",
    "4. return the chunks pertaining to the pain point\n",
    "5. concatenate all the chunks and have gpt-4 summarize the points that are relevent to your company\n",
    "6. merge this information into the assets CSV. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a5e42746-b9b7-4067-9292-f1be06db2339",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Filings:   0%|                                                                                      | 0/2 [00:00<?, ?it/s]\n",
      "Analyzing Chunks for CIK 1961:   0%|                                                                          | 0/58 [00:00<?, ?it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:   2%|█▏                                                                | 1/58 [00:00<00:50,  1.13it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:   3%|██▎                                                               | 2/58 [00:01<00:44,  1.26it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:   5%|███▍                                                              | 3/58 [00:02<00:36,  1.51it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:   7%|████▌                                                             | 4/58 [00:02<00:35,  1.54it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:   9%|█████▋                                                            | 5/58 [00:03<00:30,  1.75it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  10%|██████▊                                                           | 6/58 [00:04<00:34,  1.50it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  12%|███████▉                                                          | 7/58 [00:04<00:28,  1.79it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  14%|█████████                                                         | 8/58 [00:05<00:30,  1.62it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  16%|██████████▏                                                       | 9/58 [00:06<00:34,  1.40it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  17%|███████████▏                                                     | 10/58 [00:06<00:34,  1.39it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  19%|████████████▎                                                    | 11/58 [00:07<00:33,  1.39it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  21%|█████████████▍                                                   | 12/58 [00:08<00:33,  1.38it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  22%|██████████████▌                                                  | 13/58 [00:08<00:27,  1.66it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  24%|███████████████▋                                                 | 14/58 [00:09<00:27,  1.58it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  26%|████████████████▊                                                | 15/58 [00:10<00:33,  1.27it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  28%|█████████████████▉                                               | 16/58 [00:10<00:27,  1.51it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  29%|███████████████████                                              | 17/58 [00:11<00:25,  1.63it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  31%|████████████████████▏                                            | 18/58 [00:11<00:24,  1.63it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  33%|█████████████████████▎                                           | 19/58 [00:12<00:24,  1.58it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  34%|██████████████████████▍                                          | 20/58 [00:13<00:24,  1.54it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  36%|███████████████████████▌                                         | 21/58 [00:13<00:21,  1.73it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  38%|████████████████████████▋                                        | 22/58 [00:14<00:18,  1.95it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  40%|█████████████████████████▊                                       | 23/58 [00:14<00:17,  2.02it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  41%|██████████████████████████▉                                      | 24/58 [00:15<00:18,  1.86it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  43%|████████████████████████████                                     | 25/58 [00:15<00:16,  1.96it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  45%|█████████████████████████████▏                                   | 26/58 [00:16<00:17,  1.83it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  47%|██████████████████████████████▎                                  | 27/58 [00:16<00:15,  2.00it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  48%|███████████████████████████████▍                                 | 28/58 [00:16<00:13,  2.22it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  50%|████████████████████████████████▌                                | 29/58 [00:18<00:19,  1.49it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  52%|█████████████████████████████████▌                               | 30/58 [00:18<00:16,  1.68it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  53%|██████████████████████████████████▋                              | 31/58 [00:18<00:13,  1.94it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  55%|███████████████████████████████████▊                             | 32/58 [00:19<00:12,  2.03it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  57%|████████████████████████████████████▉                            | 33/58 [00:20<00:18,  1.37it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  59%|██████████████████████████████████████                           | 34/58 [00:21<00:16,  1.42it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  60%|███████████████████████████████████████▏                         | 35/58 [00:21<00:13,  1.66it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  62%|████████████████████████████████████████▎                        | 36/58 [00:22<00:12,  1.81it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  64%|█████████████████████████████████████████▍                       | 37/58 [00:22<00:12,  1.67it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  66%|██████████████████████████████████████████▌                      | 38/58 [00:23<00:11,  1.78it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  67%|███████████████████████████████████████████▋                     | 39/58 [00:23<00:09,  1.94it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  69%|████████████████████████████████████████████▊                    | 40/58 [00:26<00:19,  1.08s/it]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  71%|█████████████████████████████████████████████▉                   | 41/58 [00:26<00:14,  1.16it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  72%|███████████████████████████████████████████████                  | 42/58 [00:27<00:13,  1.20it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  74%|████████████████████████████████████████████████▏                | 43/58 [00:27<00:12,  1.24it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  76%|█████████████████████████████████████████████████▎               | 44/58 [00:28<00:09,  1.46it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  78%|██████████████████████████████████████████████████▍              | 45/58 [00:28<00:07,  1.63it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  79%|███████████████████████████████████████████████████▌             | 46/58 [00:29<00:06,  1.91it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  81%|████████████████████████████████████████████████████▋            | 47/58 [00:29<00:05,  2.14it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  83%|█████████████████████████████████████████████████████▊           | 48/58 [00:29<00:04,  2.23it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  84%|██████████████████████████████████████████████████████▉          | 49/58 [00:30<00:04,  2.19it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  86%|████████████████████████████████████████████████████████         | 50/58 [00:30<00:03,  2.30it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  88%|█████████████████████████████████████████████████████████▏       | 51/58 [00:30<00:02,  2.48it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  90%|██████████████████████████████████████████████████████████▎      | 52/58 [00:31<00:03,  1.81it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  91%|███████████████████████████████████████████████████████████▍     | 53/58 [00:32<00:02,  2.06it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  93%|████████████████████████████████████████████████████████████▌    | 54/58 [00:32<00:01,  2.12it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  95%|█████████████████████████████████████████████████████████████▋   | 55/58 [00:33<00:01,  1.89it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  97%|██████████████████████████████████████████████████████████████▊  | 56/58 [00:34<00:01,  1.29it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961:  98%|███████████████████████████████████████████████████████████████▉ | 57/58 [00:35<00:00,  1.51it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 1961: 100%|█████████████████████████████████████████████████████████████████| 58/58 [00:35<00:00,  1.68it/s]\u001b[A\n",
      "Processing Filings:  50%|███████████████████████████████████████                                       | 1/2 [00:36<00:36, 36.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No relevant content found for CIK 1961, ADSH 0001264931-23-000060\n",
      "Progress saved to: ../../data1/sec_data/10Q/latest_filings_with_progress_for_sic_7372.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing Chunks for CIK 320340:   0%|                                                                        | 0/95 [00:00<?, ?it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:   1%|▋                                                               | 1/95 [00:00<00:33,  2.80it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:   2%|█▎                                                              | 2/95 [00:00<00:35,  2.61it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:   3%|██                                                              | 3/95 [00:01<00:38,  2.38it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:   4%|██▋                                                             | 4/95 [00:01<00:36,  2.50it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:   5%|███▎                                                            | 5/95 [00:02<00:44,  2.03it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:   6%|████                                                            | 6/95 [00:02<00:43,  2.05it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:   7%|████▋                                                           | 7/95 [00:03<00:48,  1.82it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:   8%|█████▍                                                          | 8/95 [00:03<00:44,  1.96it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:   9%|██████                                                          | 9/95 [00:04<00:40,  2.12it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  11%|██████▋                                                        | 10/95 [00:04<00:40,  2.11it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  12%|███████▎                                                       | 11/95 [00:05<00:40,  2.09it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  13%|███████▉                                                       | 12/95 [00:05<00:41,  2.00it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  14%|████████▌                                                      | 13/95 [00:06<00:55,  1.47it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  15%|█████████▎                                                     | 14/95 [00:08<01:07,  1.21it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  16%|█████████▉                                                     | 15/95 [00:08<00:56,  1.42it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  17%|██████████▌                                                    | 16/95 [00:08<00:50,  1.58it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  18%|███████████▎                                                   | 17/95 [00:09<00:44,  1.75it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  19%|███████████▉                                                   | 18/95 [00:09<00:38,  2.03it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  20%|████████████▌                                                  | 19/95 [00:09<00:33,  2.26it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  21%|█████████████▎                                                 | 20/95 [00:10<00:31,  2.40it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  22%|█████████████▉                                                 | 21/95 [00:10<00:31,  2.36it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  23%|██████████████▌                                                | 22/95 [00:11<00:29,  2.45it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  24%|███████████████▎                                               | 23/95 [00:11<00:29,  2.46it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  25%|███████████████▉                                               | 24/95 [00:12<00:31,  2.29it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  26%|████████████████▌                                              | 25/95 [00:12<00:33,  2.11it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  27%|█████████████████▏                                             | 26/95 [00:13<00:33,  2.09it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  28%|█████████████████▉                                             | 27/95 [00:13<00:31,  2.16it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  29%|██████████████████▌                                            | 28/95 [00:14<00:34,  1.96it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  31%|███████████████████▏                                           | 29/95 [00:14<00:30,  2.20it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  32%|███████████████████▉                                           | 30/95 [00:14<00:28,  2.27it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  33%|████████████████████▌                                          | 31/95 [00:15<00:27,  2.30it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  34%|█████████████████████▏                                         | 32/95 [00:15<00:26,  2.41it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  35%|█████████████████████▉                                         | 33/95 [00:17<00:45,  1.37it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  36%|██████████████████████▌                                        | 34/95 [00:17<00:42,  1.43it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  37%|███████████████████████▏                                       | 35/95 [00:19<00:59,  1.01it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  38%|███████████████████████▊                                       | 36/95 [00:19<00:49,  1.20it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  39%|████████████████████████▌                                      | 37/95 [00:20<00:43,  1.33it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  40%|█████████████████████████▏                                     | 38/95 [00:20<00:36,  1.55it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  41%|█████████████████████████▊                                     | 39/95 [00:21<00:38,  1.46it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  42%|██████████████████████████▌                                    | 40/95 [00:22<00:34,  1.58it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  43%|███████████████████████████▏                                   | 41/95 [00:22<00:30,  1.80it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  44%|███████████████████████████▊                                   | 42/95 [00:22<00:27,  1.94it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  45%|████████████████████████████▌                                  | 43/95 [00:23<00:25,  2.05it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  46%|█████████████████████████████▏                                 | 44/95 [00:23<00:25,  2.03it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  47%|█████████████████████████████▊                                 | 45/95 [00:24<00:23,  2.15it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  48%|██████████████████████████████▌                                | 46/95 [00:24<00:22,  2.20it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  49%|███████████████████████████████▏                               | 47/95 [00:25<00:20,  2.30it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  51%|███████████████████████████████▊                               | 48/95 [00:25<00:19,  2.36it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  52%|████████████████████████████████▍                              | 49/95 [00:26<00:24,  1.87it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  53%|█████████████████████████████████▏                             | 50/95 [00:26<00:26,  1.73it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  54%|█████████████████████████████████▊                             | 51/95 [00:27<00:22,  1.99it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  55%|██████████████████████████████████▍                            | 52/95 [00:27<00:20,  2.09it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  56%|███████████████████████████████████▏                           | 53/95 [00:28<00:18,  2.32it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  57%|███████████████████████████████████▊                           | 54/95 [00:28<00:17,  2.31it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  58%|████████████████████████████████████▍                          | 55/95 [00:29<00:18,  2.11it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  59%|█████████████████████████████████████▏                         | 56/95 [00:29<00:17,  2.23it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  60%|█████████████████████████████████████▊                         | 57/95 [00:32<00:49,  1.31s/it]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  61%|██████████████████████████████████████▍                        | 58/95 [00:33<00:38,  1.05s/it]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  62%|███████████████████████████████████████▏                       | 59/95 [00:33<00:31,  1.14it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  63%|███████████████████████████████████████▊                       | 60/95 [00:34<00:26,  1.30it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  64%|████████████████████████████████████████▍                      | 61/95 [00:34<00:22,  1.52it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  65%|█████████████████████████████████████████                      | 62/95 [00:35<00:20,  1.62it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  66%|█████████████████████████████████████████▊                     | 63/95 [00:35<00:17,  1.81it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  67%|██████████████████████████████████████████▍                    | 64/95 [00:35<00:14,  2.07it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  68%|███████████████████████████████████████████                    | 65/95 [00:36<00:14,  2.05it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  69%|███████████████████████████████████████████▊                   | 66/95 [00:37<00:16,  1.76it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  71%|████████████████████████████████████████████▍                  | 67/95 [00:37<00:14,  1.93it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  72%|█████████████████████████████████████████████                  | 68/95 [00:38<00:17,  1.57it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  73%|█████████████████████████████████████████████▊                 | 69/95 [00:38<00:14,  1.84it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  74%|██████████████████████████████████████████████▍                | 70/95 [00:39<00:13,  1.89it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  75%|███████████████████████████████████████████████                | 71/95 [00:41<00:27,  1.15s/it]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  76%|███████████████████████████████████████████████▋               | 72/95 [00:42<00:22,  1.04it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  77%|████████████████████████████████████████████████▍              | 73/95 [00:42<00:17,  1.28it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  78%|█████████████████████████████████████████████████              | 74/95 [00:43<00:13,  1.51it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  79%|█████████████████████████████████████████████████▋             | 75/95 [00:43<00:12,  1.66it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  80%|██████████████████████████████████████████████████▍            | 76/95 [00:43<00:10,  1.80it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  81%|███████████████████████████████████████████████████            | 77/95 [00:44<00:09,  1.91it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  82%|███████████████████████████████████████████████████▋           | 78/95 [00:44<00:08,  1.98it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  83%|████████████████████████████████████████████████████▍          | 79/95 [00:45<00:07,  2.13it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  84%|█████████████████████████████████████████████████████          | 80/95 [00:45<00:07,  2.13it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  85%|█████████████████████████████████████████████████████▋         | 81/95 [00:46<00:07,  1.91it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  86%|██████████████████████████████████████████████████████▍        | 82/95 [00:46<00:06,  2.05it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  87%|███████████████████████████████████████████████████████        | 83/95 [00:47<00:05,  2.13it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  88%|███████████████████████████████████████████████████████▋       | 84/95 [00:47<00:05,  1.89it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  89%|████████████████████████████████████████████████████████▎      | 85/95 [00:48<00:04,  2.13it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  91%|█████████████████████████████████████████████████████████      | 86/95 [00:48<00:03,  2.35it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  92%|█████████████████████████████████████████████████████████▋     | 87/95 [00:49<00:03,  2.25it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  93%|██████████████████████████████████████████████████████████▎    | 88/95 [00:49<00:03,  2.30it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  94%|███████████████████████████████████████████████████████████    | 89/95 [00:49<00:02,  2.55it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  95%|███████████████████████████████████████████████████████████▋   | 90/95 [00:50<00:02,  2.49it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  96%|████████████████████████████████████████████████████████████▎  | 91/95 [00:50<00:01,  2.18it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  97%|█████████████████████████████████████████████████████████████  | 92/95 [00:51<00:01,  2.11it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  98%|█████████████████████████████████████████████████████████████▋ | 93/95 [00:51<00:00,  2.05it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340:  99%|██████████████████████████████████████████████████████████████▎| 94/95 [00:52<00:00,  2.29it/s]\u001b[A\n",
      "Analyzing Chunks for CIK 320340: 100%|███████████████████████████████████████████████████████████████| 95/95 [00:53<00:00,  1.49it/s]\u001b[A\n",
      "Processing Filings: 100%|██████████████████████████████████████████████████████████████████████████████| 2/2 [02:17<00:00, 68.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for CIK 320340, ADSH 0001437749-23-029656:\n",
      "Based on the provided text, several cybersecurity pain points for the enterprise customer can be identified. These pain points are critical issues that the company is facing or could face that relate directly to the cybersecurity landscape and could have significant repercussions on their operations and profitability.\n",
      "\n",
      "1. **Regulatory Compliance Risks**: The company acknowledges the need to comply with applicable regulations and processing standards. Failure to meet these standards could result in financial penalties or other sanctions that would negatively impact their business. This highlights the pain point of maintaining compliance in a landscape where regulatory requirements are often complex and ever-changing.\n",
      "\n",
      "2. **Data Breach Vulnerability**: There is a concern about the potential for a security breach that could expose confidential information of the company’s customers' account holders. The impact of such a breach would not only be the immediate exposure of sensitive data but also the longer-term erosion of customer trust and potential legal consequences.\n",
      "\n",
      "3. **Ransomware Threats**: The risk of hackers seizing the company's digital infrastructure and holding it for ransom is identified as a critical pain point. This not only disrupts operations but could also lead to substantial financial losses, particularly if the losses exceed the company's insurance coverage.\n",
      "\n",
      "4. **Cyber Risk Events**: Other unspecified cyber risk events are mentioned as potential sources of material losses. This suggests a broader concern for various forms of cyber threats that could compromise the company's digital assets and lead to direct or indirect financial damage.\n",
      "\n",
      "5. **Quality Control in Software Development**: Issues with software errors or poor-quality control are noted as factors that could delay product releases, increase costs, and result in customer dissatisfaction or loss. This points to the need for robust development practices and quality assurance measures to prevent such setbacks.\n",
      "\n",
      "6. **Product Adaptability**: Changes in regulations, especially in areas like data privacy and financial transactions, could necessitate modifications to the company's products and services. This adaptability is a pain point as it could lead to increased costs and might affect customer relationships or the ability to acquire new customers.\n",
      "\n",
      "7. **Cash Flow Concerns**: Delays in customer payments are highlighted as a factor that could negatively impact the company's cash requirements and profitability. This suggests that the company is looking for solutions that could minimize such risks or help them manage their cash flow more effectively.\n",
      "\n",
      "8. **Competitive Pressures**: The company is aware of the competitive landscape, including pricing challenges, shifts in customer needs and preferences, and offerings from competitors. The pain point here is the risk of losing potential customers to competitors who may provide alternative solutions that better meet their current requirements.\n",
      "\n",
      "In positioning our digital security solutions to this company, we should emphasize how our products can address these pain points by:\n",
      "\n",
      "- Ensuring regulatory compliance through robust security frameworks.\n",
      "- Providing advanced data breach prevention measures to safeguard sensitive customer data.\n",
      "- Offering solutions to protect against ransomware and other cyber threats.\n",
      "- Emphasizing the high quality and reliability of our software solutions to avoid delays and additional costs.\n",
      "- Demonstrating the adaptability of our solutions to meet evolving regulatory and market demands.\n",
      "- Highlighting how our solutions can help streamline operations and potentially improve cash flow management.\n",
      "- Showcasing our competitive edge in innovation, customer service, and value to differentiate from other market offerings.\n",
      "\n",
      "By focusing on these areas, we can illustrate the concrete benefits our cybersecurity solutions can provide, helping to alleviate the enterprise customer's pain points and enhancing their overall security posture.\n",
      "Progress saved to: ../../data1/sec_data/10Q/latest_filings_with_progress_for_sic_7372.csv\n",
      "Progress saved to: ../../data1/sec_data/10Q/latest_filings_with_progress_for_sic_7372.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def fetch_html_content(cik, adsh, instance):\n",
    "    \"\"\"Fetches the HTML content of the SEC filing.\"\"\"\n",
    "    html_instance = instance.replace(\"_htm.xml\", \".htm\")\n",
    "    url = f'https://www.sec.gov/Archives/edgar/data/{cik}/{adsh.replace(\"-\", \"\")}/{html_instance}'\n",
    "    response = requests.get(url, headers={'User-Agent': 'bjorn', 'From': 'Bjorn.T.Kringlen@gmail.com'})\n",
    "    if response.status_code == 200:\n",
    "        return response.content\n",
    "    else:\n",
    "        logging.error(f\"Failed to fetch HTML content for CIK {cik}, ADSH {adsh}\")\n",
    "        return None\n",
    "\n",
    "openai_api_key = open_ai_key  \n",
    "client = OpenAI(api_key = open_ai_key)\n",
    "\n",
    "def chunk_text(text, chunk_size=600):\n",
    "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "def analyze_chunk_with_gpt(chunk):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": extraction_prompt},\n",
    "            {\"role\": \"user\", \"content\": chunk}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def summarize_with_gpt(text):\n",
    "    try:\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": summary_prompt},\n",
    "            {\"role\": \"user\", \"content\": text}\n",
    "        ]\n",
    "        response = client.chat.completions.create(\n",
    "            model= \"gpt-4-1106-preview\",  \n",
    "            messages=messages,\n",
    "            temperature=.7\n",
    "        )\n",
    "        response_message = response.choices[0].message.content\n",
    "        return response_message.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return \"Error summarizing text.\"\n",
    "\n",
    "csv_output_path = Path(f'../../data1/sec_data/10Q/latest_filings_with_progress_for_sic_{sic_code}.csv')\n",
    "\n",
    "def save_progress():\n",
    "    latest_filings_subset.to_csv(csv_output_path, index=False)\n",
    "    print(f\"Progress saved to: {csv_output_path}\")\n",
    "\n",
    "csv_output_path = Path(f'../../data1/sec_data/10Q/latest_filings_with_progress_for_sic_{sic_code}.csv')\n",
    "if csv_output_path.exists():\n",
    "    latest_filings_subset = pd.read_csv(csv_output_path)\n",
    "else:\n",
    "    # Initialize your DataFrame here\n",
    "    latest_filings_subset =  pd.DataFrame(columns=['CIK', 'ADSH', 'Instance', 'Relevant_Chunks', 'GPT4_Summary', 'Processed'])\n",
    "\n",
    "latest_filings_subset = latest_filings.head(number_of_filings_to_process)\n",
    "latest_filings_subset['Relevant_Chunks'] = None\n",
    "latest_filings_subset['GPT4_Summary'] = None\n",
    "latest_filings_subset['Processed'] = 0\n",
    "\n",
    "# Process each filing with a progress bar\n",
    "for index, row in tqdm(latest_filings_subset.iterrows(), total=latest_filings_subset.shape[0], desc=\"Processing Filings\"):\n",
    "    if row['Processed'] == 1:\n",
    "        continue  \n",
    "\n",
    "    cik = row['cik']\n",
    "    adsh = row['adsh']\n",
    "    instance = row['instance']\n",
    "\n",
    "    html_content = fetch_html_content(cik, adsh, instance)\n",
    "    if html_content:\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        text_content = ' '.join(para.get_text(strip=True) for para in soup.find_all('p'))\n",
    "        cleaned_text = re.sub(r'\\s{2,}', ' ', text_content)\n",
    "\n",
    "        chunks = chunk_text(cleaned_text)\n",
    "        relevant_chunks = []\n",
    "\n",
    "        for chunk in tqdm(chunks, desc=f\"Analyzing Chunks for CIK {cik}\", leave=False):\n",
    "            if analyze_chunk_with_gpt(chunk) == '1':\n",
    "                relevant_chunks.append(chunk)\n",
    "\n",
    "        if relevant_chunks:\n",
    "            concatenated_text = ' '.join(relevant_chunks)\n",
    "            summary = summarize_with_gpt(concatenated_text)\n",
    "            latest_filings_subset.at[index, 'Relevant_Chunks'] = concatenated_text\n",
    "            latest_filings_subset.at[index, 'GPT4_Summary'] = summary\n",
    "            latest_filings_subset.at[index, 'Processed'] = 1\n",
    "            print(f\"Summary for CIK {cik}, ADSH {adsh}:\")\n",
    "            print(summary)\n",
    "        else:\n",
    "            print(f\"No relevant content found for CIK {cik}, ADSH {adsh}\")\n",
    "            latest_filings_subset.at[index, 'Processed'] = -1 # Mark if no relevant content\n",
    "\n",
    "        save_progress()  \n",
    "\n",
    "save_progress()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1dfc62-3895-4bbe-9b83-646f219e8542",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
